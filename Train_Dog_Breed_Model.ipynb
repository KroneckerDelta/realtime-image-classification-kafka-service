{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
    "from keras.layers.pooling import GlobalAveragePooling2D\n",
    "from keras.layers.merge import Concatenate\n",
    "from keras.layers import Input, Dense, Flatten\n",
    "from keras.layers.core import Dropout, Activation\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.models import Model\n",
    "from keras.preprocessing import image  \n",
    "from keras.utils import np_utils\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.datasets import load_files\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from tqdm import tqdm   \n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import os.path\n",
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download file if not already in directory\n",
    "# Go to https://www.kaggle.com/c/dog-breed-identification/data download and unpack train.zip and labels.csv.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    assert os.path.isdir('dogImages/train') and os.path.isdir('dogImages/test') and os.path.isdir('dogImages/valid')\n",
    "except:\n",
    "    print(\"Download the images from https://s3-us-west-1.amazonaws.com/udacity-aind/dog-project/dogImages.zip and unpack.\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(path):\n",
    "    data = load_files(path)\n",
    "    dog_files = np.array(data['filenames'])\n",
    "    dog_targets = np_utils.to_categorical(np.array(data['target']), 133)\n",
    "    return dog_files, dog_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_files, train_targets = load_dataset('dogImages/train')\n",
    "valid_files, valid_targets = load_dataset('dogImages/valid')\n",
    "test_files, test_targets = load_dataset('dogImages/test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dog_names = [item[20:-1] for item in sorted(glob(\"dogImages/train/*/\"))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def path_to_tensor(img_path):\n",
    "    # loads RGB image as PIL.Image.Image type\n",
    "    img = image.load_img(img_path, target_size=(299, 299))\n",
    "    # convert PIL.Image.Image type to 3D tensor with shape (299, 299, 3)\n",
    "    x = image.img_to_array(img)\n",
    "    # convert 3D tensor to 4D tensor with shape (1, 299, 299, 3) and return 4D tensor\n",
    "    return np.expand_dims(x, axis=0)\n",
    "\n",
    "def paths_to_tensor(img_paths):\n",
    "    list_of_tensors = [path_to_tensor(img_path) for img_path in tqdm(img_paths)]\n",
    "    return np.vstack(list_of_tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6680/6680 [01:24<00:00, 78.72it/s] \n",
      "100%|██████████| 835/835 [00:15<00:00, 53.07it/s]\n",
      "100%|██████████| 836/836 [00:06<00:00, 120.57it/s]\n"
     ]
    }
   ],
   "source": [
    "from PIL import ImageFile                            \n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True                 \n",
    "\n",
    "# pre-process the data for Keras\n",
    "train_tensors = paths_to_tensor(train_files).astype('float32')\n",
    "valid_tensors = paths_to_tensor(valid_files).astype('float32')\n",
    "test_tensors = paths_to_tensor(test_files).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "InceptionV3 TrainSet shape (8, 8, 2048)\n",
      "InceptionV3 TestSet shape (8, 8, 2048)\n",
      "InceptionV3 ValidSet shape (8, 8, 2048)\n"
     ]
    }
   ],
   "source": [
    "inceptionV3 = InceptionV3(weights='imagenet', include_top=False)\n",
    "# Inception Model\n",
    "train_preprocessed_input = preprocess_input(train_tensors)\n",
    "train_preprocessed_tensors = inceptionV3.predict(train_preprocessed_input, batch_size=32)\n",
    "print(\"InceptionV3 TrainSet shape\", train_preprocessed_tensors.shape[1:])\n",
    "test_preprocessed_input = preprocess_input(test_tensors)\n",
    "test_preprocessed_tensors = inceptionV3.predict(test_preprocessed_input, batch_size=32)\n",
    "print(\"InceptionV3 TestSet shape\", test_preprocessed_tensors.shape[1:])\n",
    "valid_preprocessed_input = preprocess_input(valid_tensors)\n",
    "valid_preprocessed_tensors = inceptionV3.predict(valid_preprocessed_input, batch_size=32)\n",
    "print(\"InceptionV3 ValidSet shape\", valid_preprocessed_tensors.shape[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         (None, 8, 8, 2048)        0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_4 ( (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 512)               1048576   \n",
      "_________________________________________________________________\n",
      "batch_normalization_101 (Bat (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "activation_101 (Activation)  (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 256)               131072    \n",
      "_________________________________________________________________\n",
      "batch_normalization_102 (Bat (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "activation_102 (Activation)  (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 133)               34181     \n",
      "=================================================================\n",
      "Total params: 1,216,901\n",
      "Trainable params: 1,215,365\n",
      "Non-trainable params: 1,536\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "net_input = Input(shape=(8, 8, 2048))\n",
    "net = GlobalAveragePooling2D()(net_input)\n",
    "net = Dense(512, use_bias=False, kernel_initializer='uniform')(net)\n",
    "net = BatchNormalization()(net)\n",
    "net = Activation(\"relu\")(net)\n",
    "net = Dropout(0.5)(net)\n",
    "net = Dense(256, use_bias=False, kernel_initializer='uniform')(net)\n",
    "net = BatchNormalization()(net)\n",
    "net = Activation(\"relu\")(net)\n",
    "net = Dropout(0.5)(net)\n",
    "net = Dense(133, kernel_initializer='uniform', activation=\"softmax\")(net)\n",
    "\n",
    "dog_breed_model = Model(inputs=[net_input], outputs=[net])\n",
    "dog_breed_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6680 samples, validate on 835 samples\n",
      "Epoch 1/50\n",
      "6668/6680 [============================>.] - ETA: 0s - loss: 4.3307 - acc: 0.1624Epoch 00000: val_loss improved from inf to 2.85498, saving model to dogbreed_model.hdf5\n",
      "6680/6680 [==============================] - 33s - loss: 4.3297 - acc: 0.1627 - val_loss: 2.8550 - val_acc: 0.6838\n",
      "Epoch 2/50\n",
      "6668/6680 [============================>.] - ETA: 0s - loss: 3.3206 - acc: 0.4354Epoch 00001: val_loss improved from 2.85498 to 1.72044, saving model to dogbreed_model.hdf5\n",
      "6680/6680 [==============================] - 32s - loss: 3.3203 - acc: 0.4353 - val_loss: 1.7204 - val_acc: 0.7365\n",
      "Epoch 3/50\n",
      "6676/6680 [============================>.] - ETA: 0s - loss: 2.5446 - acc: 0.5598Epoch 00002: val_loss improved from 1.72044 to 1.09060, saving model to dogbreed_model.hdf5\n",
      "6680/6680 [==============================] - 31s - loss: 2.5439 - acc: 0.5599 - val_loss: 1.0906 - val_acc: 0.7605\n",
      "Epoch 4/50\n",
      "6676/6680 [============================>.] - ETA: 0s - loss: 1.9600 - acc: 0.6333Epoch 00003: val_loss improved from 1.09060 to 0.78950, saving model to dogbreed_model.hdf5\n",
      "6680/6680 [==============================] - 30s - loss: 1.9598 - acc: 0.6334 - val_loss: 0.7895 - val_acc: 0.7976\n",
      "Epoch 5/50\n",
      "6672/6680 [============================>.] - ETA: 0s - loss: 1.5529 - acc: 0.6793Epoch 00004: val_loss improved from 0.78950 to 0.61055, saving model to dogbreed_model.hdf5\n",
      "6680/6680 [==============================] - 31s - loss: 1.5520 - acc: 0.6796 - val_loss: 0.6106 - val_acc: 0.8359\n",
      "Epoch 6/50\n",
      "6668/6680 [============================>.] - ETA: 0s - loss: 1.2785 - acc: 0.7130Epoch 00005: val_loss improved from 0.61055 to 0.51677, saving model to dogbreed_model.hdf5\n",
      "6680/6680 [==============================] - 31s - loss: 1.2787 - acc: 0.7126 - val_loss: 0.5168 - val_acc: 0.8527\n",
      "Epoch 7/50\n",
      "6668/6680 [============================>.] - ETA: 0s - loss: 1.1153 - acc: 0.7340Epoch 00006: val_loss improved from 0.51677 to 0.45454, saving model to dogbreed_model.hdf5\n",
      "6680/6680 [==============================] - 30s - loss: 1.1163 - acc: 0.7337 - val_loss: 0.4545 - val_acc: 0.8647\n",
      "Epoch 8/50\n",
      "6676/6680 [============================>.] - ETA: 0s - loss: 0.9976 - acc: 0.7506Epoch 00007: val_loss improved from 0.45454 to 0.43176, saving model to dogbreed_model.hdf5\n",
      "6680/6680 [==============================] - 31s - loss: 0.9977 - acc: 0.7504 - val_loss: 0.4318 - val_acc: 0.8659\n",
      "Epoch 9/50\n",
      "6676/6680 [============================>.] - ETA: 0s - loss: 0.9191 - acc: 0.7573Epoch 00008: val_loss improved from 0.43176 to 0.41171, saving model to dogbreed_model.hdf5\n",
      "6680/6680 [==============================] - 31s - loss: 0.9194 - acc: 0.7572 - val_loss: 0.4117 - val_acc: 0.8599\n",
      "Epoch 10/50\n",
      "6668/6680 [============================>.] - ETA: 0s - loss: 0.8500 - acc: 0.7743Epoch 00009: val_loss improved from 0.41171 to 0.39043, saving model to dogbreed_model.hdf5\n",
      "6680/6680 [==============================] - 31s - loss: 0.8521 - acc: 0.7738 - val_loss: 0.3904 - val_acc: 0.8790\n",
      "Epoch 11/50\n",
      "6676/6680 [============================>.] - ETA: 0s - loss: 0.8185 - acc: 0.7755Epoch 00010: val_loss improved from 0.39043 to 0.37728, saving model to dogbreed_model.hdf5\n",
      "6680/6680 [==============================] - 31s - loss: 0.8186 - acc: 0.7754 - val_loss: 0.3773 - val_acc: 0.8707\n",
      "Epoch 12/50\n",
      "6668/6680 [============================>.] - ETA: 0s - loss: 0.7543 - acc: 0.7903Epoch 00011: val_loss improved from 0.37728 to 0.36792, saving model to dogbreed_model.hdf5\n",
      "6680/6680 [==============================] - 31s - loss: 0.7535 - acc: 0.7906 - val_loss: 0.3679 - val_acc: 0.8814\n",
      "Epoch 13/50\n",
      "6672/6680 [============================>.] - ETA: 0s - loss: 0.7416 - acc: 0.7924Epoch 00012: val_loss did not improve\n",
      "6680/6680 [==============================] - 31s - loss: 0.7415 - acc: 0.7925 - val_loss: 0.3761 - val_acc: 0.8778\n",
      "Epoch 14/50\n",
      "6668/6680 [============================>.] - ETA: 0s - loss: 0.7294 - acc: 0.7930Epoch 00013: val_loss improved from 0.36792 to 0.35708, saving model to dogbreed_model.hdf5\n",
      "6680/6680 [==============================] - 31s - loss: 0.7288 - acc: 0.7933 - val_loss: 0.3571 - val_acc: 0.8850\n",
      "Epoch 15/50\n",
      "6668/6680 [============================>.] - ETA: 0s - loss: 0.6673 - acc: 0.8040Epoch 00014: val_loss improved from 0.35708 to 0.35533, saving model to dogbreed_model.hdf5\n",
      "6680/6680 [==============================] - 31s - loss: 0.6671 - acc: 0.8039 - val_loss: 0.3553 - val_acc: 0.8814\n",
      "Epoch 16/50\n",
      "6676/6680 [============================>.] - ETA: 0s - loss: 0.6746 - acc: 0.7987Epoch 00015: val_loss did not improve\n",
      "6680/6680 [==============================] - 31s - loss: 0.6744 - acc: 0.7988 - val_loss: 0.3572 - val_acc: 0.8886\n",
      "Epoch 17/50\n",
      "6672/6680 [============================>.] - ETA: 0s - loss: 0.6472 - acc: 0.8128Epoch 00016: val_loss did not improve\n",
      "6680/6680 [==============================] - 31s - loss: 0.6472 - acc: 0.8127 - val_loss: 0.3646 - val_acc: 0.8922\n",
      "Epoch 18/50\n",
      "6676/6680 [============================>.] - ETA: 0s - loss: 0.6297 - acc: 0.8149Epoch 00017: val_loss improved from 0.35533 to 0.35499, saving model to dogbreed_model.hdf5\n",
      "6680/6680 [==============================] - 31s - loss: 0.6294 - acc: 0.8150 - val_loss: 0.3550 - val_acc: 0.8898\n",
      "Epoch 19/50\n",
      "6668/6680 [============================>.] - ETA: 0s - loss: 0.6255 - acc: 0.8100Epoch 00018: val_loss did not improve\n",
      "6680/6680 [==============================] - 31s - loss: 0.6252 - acc: 0.8102 - val_loss: 0.3653 - val_acc: 0.8886\n",
      "Epoch 20/50\n",
      "6668/6680 [============================>.] - ETA: 0s - loss: 0.6031 - acc: 0.8208Epoch 00019: val_loss improved from 0.35499 to 0.34325, saving model to dogbreed_model.hdf5\n",
      "6680/6680 [==============================] - 31s - loss: 0.6031 - acc: 0.8210 - val_loss: 0.3433 - val_acc: 0.8994\n",
      "Epoch 21/50\n",
      "6668/6680 [============================>.] - ETA: 0s - loss: 0.5931 - acc: 0.8172Epoch 00020: val_loss did not improve\n",
      "6680/6680 [==============================] - 31s - loss: 0.5927 - acc: 0.8174 - val_loss: 0.3498 - val_acc: 0.8934\n",
      "Epoch 22/50\n",
      "6672/6680 [============================>.] - ETA: 0s - loss: 0.5951 - acc: 0.8194Epoch 00021: val_loss did not improve\n",
      "6680/6680 [==============================] - 31s - loss: 0.5954 - acc: 0.8195 - val_loss: 0.3513 - val_acc: 0.8886\n",
      "Epoch 23/50\n",
      "6676/6680 [============================>.] - ETA: 0s - loss: 0.5650 - acc: 0.8234Epoch 00022: val_loss did not improve\n",
      "6680/6680 [==============================] - 31s - loss: 0.5652 - acc: 0.8234 - val_loss: 0.3449 - val_acc: 0.8958\n",
      "Epoch 24/50\n",
      "6676/6680 [============================>.] - ETA: 0s - loss: 0.5793 - acc: 0.8194Epoch 00023: val_loss did not improve\n",
      "6680/6680 [==============================] - 31s - loss: 0.5792 - acc: 0.8193 - val_loss: 0.3453 - val_acc: 0.8910\n",
      "Epoch 25/50\n",
      "6676/6680 [============================>.] - ETA: 0s - loss: 0.5358 - acc: 0.8337Epoch 00024: val_loss did not improve\n",
      "6680/6680 [==============================] - 31s - loss: 0.5359 - acc: 0.8335 - val_loss: 0.3527 - val_acc: 0.8922\n",
      "Epoch 26/50\n",
      "6676/6680 [============================>.] - ETA: 0s - loss: 0.5465 - acc: 0.8300Epoch 00025: val_loss did not improve\n",
      "6680/6680 [==============================] - 31s - loss: 0.5468 - acc: 0.8296 - val_loss: 0.3538 - val_acc: 0.8910\n",
      "Epoch 27/50\n",
      "6676/6680 [============================>.] - ETA: 0s - loss: 0.5371 - acc: 0.8306Epoch 00026: val_loss did not improve\n",
      "6680/6680 [==============================] - 31s - loss: 0.5370 - acc: 0.8305 - val_loss: 0.3513 - val_acc: 0.8898\n",
      "Epoch 28/50\n",
      "6668/6680 [============================>.] - ETA: 0s - loss: 0.5421 - acc: 0.8316Epoch 00027: val_loss did not improve\n",
      "6680/6680 [==============================] - 31s - loss: 0.5423 - acc: 0.8316 - val_loss: 0.3510 - val_acc: 0.8958\n",
      "Epoch 29/50\n",
      "6676/6680 [============================>.] - ETA: 0s - loss: 0.5281 - acc: 0.8400Epoch 00028: val_loss did not improve\n",
      "6680/6680 [==============================] - 31s - loss: 0.5279 - acc: 0.8401 - val_loss: 0.3480 - val_acc: 0.8922\n",
      "Epoch 30/50\n",
      "6668/6680 [============================>.] - ETA: 0s - loss: 0.5360 - acc: 0.8296Epoch 00029: val_loss did not improve\n",
      "6680/6680 [==============================] - 30s - loss: 0.5357 - acc: 0.8298 - val_loss: 0.3595 - val_acc: 0.8862\n",
      "Epoch 31/50\n",
      "6672/6680 [============================>.] - ETA: 0s - loss: 0.5199 - acc: 0.8363Epoch 00030: val_loss did not improve\n",
      "6680/6680 [==============================] - 30s - loss: 0.5194 - acc: 0.8365 - val_loss: 0.3507 - val_acc: 0.8934\n",
      "Epoch 32/50\n",
      "6676/6680 [============================>.] - ETA: 0s - loss: 0.5069 - acc: 0.8429Epoch 00031: val_loss did not improve\n",
      "6680/6680 [==============================] - 30s - loss: 0.5073 - acc: 0.8427 - val_loss: 0.3665 - val_acc: 0.8886\n",
      "Epoch 33/50\n",
      "6676/6680 [============================>.] - ETA: 0s - loss: 0.4878 - acc: 0.8489Epoch 00032: val_loss did not improve\n",
      "6680/6680 [==============================] - 34s - loss: 0.4879 - acc: 0.8487 - val_loss: 0.3681 - val_acc: 0.8970\n",
      "Epoch 34/50\n",
      "6668/6680 [============================>.] - ETA: 0s - loss: 0.4883 - acc: 0.8421Epoch 00033: val_loss did not improve\n",
      "6680/6680 [==============================] - 31s - loss: 0.4891 - acc: 0.8419 - val_loss: 0.3713 - val_acc: 0.8886\n",
      "Epoch 35/50\n",
      "6672/6680 [============================>.] - ETA: 0s - loss: 0.4829 - acc: 0.8464Epoch 00034: val_loss did not improve\n",
      "6680/6680 [==============================] - 31s - loss: 0.4827 - acc: 0.8464 - val_loss: 0.3619 - val_acc: 0.8886\n",
      "Epoch 36/50\n",
      "6672/6680 [============================>.] - ETA: 0s - loss: 0.4749 - acc: 0.8423Epoch 00035: val_loss did not improve\n",
      "6680/6680 [==============================] - 31s - loss: 0.4759 - acc: 0.8421 - val_loss: 0.3617 - val_acc: 0.8934\n",
      "Epoch 37/50\n",
      "6672/6680 [============================>.] - ETA: 0s - loss: 0.4520 - acc: 0.8543Epoch 00036: val_loss did not improve\n",
      "6680/6680 [==============================] - 32s - loss: 0.4517 - acc: 0.8545 - val_loss: 0.3660 - val_acc: 0.8922\n",
      "Epoch 38/50\n",
      "6668/6680 [============================>.] - ETA: 0s - loss: 0.4766 - acc: 0.8511Epoch 00037: val_loss did not improve\n",
      "6680/6680 [==============================] - 31s - loss: 0.4773 - acc: 0.8507 - val_loss: 0.3652 - val_acc: 0.8970\n",
      "Epoch 39/50\n",
      "6668/6680 [============================>.] - ETA: 0s - loss: 0.4629 - acc: 0.8550Epoch 00038: val_loss did not improve\n",
      "6680/6680 [==============================] - 31s - loss: 0.4626 - acc: 0.8551 - val_loss: 0.3474 - val_acc: 0.8958\n",
      "Epoch 40/50\n",
      "6672/6680 [============================>.] - ETA: 0s - loss: 0.4839 - acc: 0.8458Epoch 00039: val_loss did not improve\n",
      "6680/6680 [==============================] - 31s - loss: 0.4836 - acc: 0.8460 - val_loss: 0.3553 - val_acc: 0.8886\n",
      "Epoch 41/50\n",
      "6676/6680 [============================>.] - ETA: 0s - loss: 0.4612 - acc: 0.8558Epoch 00040: val_loss did not improve\n",
      "6680/6680 [==============================] - 33s - loss: 0.4614 - acc: 0.8557 - val_loss: 0.3591 - val_acc: 0.8922\n",
      "Epoch 42/50\n",
      "6676/6680 [============================>.] - ETA: 0s - loss: 0.4803 - acc: 0.8474Epoch 00041: val_loss did not improve\n",
      "6680/6680 [==============================] - 32s - loss: 0.4801 - acc: 0.8475 - val_loss: 0.3566 - val_acc: 0.8898\n",
      "Epoch 43/50\n",
      "6676/6680 [============================>.] - ETA: 0s - loss: 0.4494 - acc: 0.8616Epoch 00042: val_loss did not improve\n",
      "6680/6680 [==============================] - 31s - loss: 0.4495 - acc: 0.8615 - val_loss: 0.3535 - val_acc: 0.8898\n",
      "Epoch 44/50\n",
      "6676/6680 [============================>.] - ETA: 0s - loss: 0.4415 - acc: 0.8577Epoch 00043: val_loss did not improve\n",
      "6680/6680 [==============================] - 32s - loss: 0.4417 - acc: 0.8576 - val_loss: 0.3445 - val_acc: 0.9018\n",
      "Epoch 45/50\n",
      "6672/6680 [============================>.] - ETA: 0s - loss: 0.4400 - acc: 0.8638Epoch 00044: val_loss did not improve\n",
      "6680/6680 [==============================] - 32s - loss: 0.4397 - acc: 0.8639 - val_loss: 0.3523 - val_acc: 0.8934\n",
      "Epoch 46/50\n",
      "6672/6680 [============================>.] - ETA: 0s - loss: 0.4429 - acc: 0.8566Epoch 00045: val_loss did not improve\n",
      "6680/6680 [==============================] - 31s - loss: 0.4425 - acc: 0.8566 - val_loss: 0.3605 - val_acc: 0.8934\n",
      "Epoch 47/50\n",
      "6672/6680 [============================>.] - ETA: 0s - loss: 0.4284 - acc: 0.8590Epoch 00046: val_loss did not improve\n",
      "6680/6680 [==============================] - 31s - loss: 0.4283 - acc: 0.8591 - val_loss: 0.3541 - val_acc: 0.8970\n",
      "Epoch 48/50\n",
      "6676/6680 [============================>.] - ETA: 0s - loss: 0.4473 - acc: 0.8562Epoch 00047: val_loss improved from 0.34325 to 0.34212, saving model to dogbreed_model.hdf5\n",
      "6680/6680 [==============================] - 32s - loss: 0.4473 - acc: 0.8563 - val_loss: 0.3421 - val_acc: 0.8970\n",
      "Epoch 49/50\n",
      "6672/6680 [============================>.] - ETA: 0s - loss: 0.4256 - acc: 0.8663Epoch 00048: val_loss did not improve\n",
      "6680/6680 [==============================] - 31s - loss: 0.4257 - acc: 0.8663 - val_loss: 0.3600 - val_acc: 0.8934\n",
      "Epoch 50/50\n",
      "6672/6680 [============================>.] - ETA: 0s - loss: 0.4329 - acc: 0.8641Epoch 00049: val_loss did not improve\n",
      "6680/6680 [==============================] - 31s - loss: 0.4335 - acc: 0.8639 - val_loss: 0.3538 - val_acc: 0.8982\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff7d82faef0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dog_breed_model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=1e-04), metrics=['accuracy'])\n",
    "checkpointer = ModelCheckpoint(filepath='dogbreed_model.hdf5', verbose=1, save_best_only=True)\n",
    "dog_breed_model.fit([train_preprocessed_tensors], train_targets, \n",
    "          validation_data=([valid_preprocessed_tensors], valid_targets),\n",
    "          epochs=50, batch_size=4, callbacks=[checkpointer], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 89.1148%\n"
     ]
    }
   ],
   "source": [
    "dog_breed_model.load_weights('dogbreed_model.hdf5') # in case you haven't train it \n",
    "predictions = dog_breed_model.predict([test_preprocessed_tensors])\n",
    "breed_predictions = [np.argmax(prediction) for prediction in predictions]\n",
    "breed_true_labels = [np.argmax(true_label) for true_label in test_targets]\n",
    "print('Test accuracy: %.4f%%' % (accuracy_score(breed_true_labels, breed_predictions) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(dog_names, open('dogbreed_labels.pickle', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
